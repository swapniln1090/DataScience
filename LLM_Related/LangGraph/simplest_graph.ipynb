{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### *This Code is Ran in Google Colab*\n",
        "\n",
        "Hence, You might need to install below libraries in your local machine."
      ],
      "metadata": {
        "id": "r_1V9Nf3lXc1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-0vFaDJcyB3R"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs3BGVRBcpfN",
        "outputId": "cc2b64af-d44f-4dfe-acb9-44cd53d49891"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.3.19)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.54.4)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain_openai) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.17->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.17->langchain_openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Downloading langchain_openai-0.2.9-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.2.9 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Simple Graph Overview**\n",
        "\n",
        "Here, we are trying to create simple graph with below flow -\n",
        "\n",
        "###*User Input* *--->* *Function 1* *----Edge--->* *Function 2* *--->* *Graph Output*\n"
      ],
      "metadata": {
        "id": "GNozqmsq-MGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function1(input1):\n",
        "  return input1 + \" First Function\"\n",
        "\n",
        "def function2(input2):\n",
        "  return input2 + \" to Second Function\""
      ],
      "metadata": {
        "id": "DgKaJHcmWCtU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import Graph, StateGraph , START, END"
      ],
      "metadata": {
        "id": "-GNLPOJEWDJA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKuvickeYVF0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "builder = Graph()\n",
        "\n",
        "builder.add_node(\"node1\", function1)\n",
        "builder.add_node(\"node2\", function2)\n",
        "\n",
        "builder.add_edge( \"node1\", \"node2\")\n",
        "builder.set_entry_point(\"node1\")\n",
        "builder.set_finish_point(\"node2\")\n",
        "\n",
        "app = builder.compile()\n",
        "\n",
        "# View\n",
        "#display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "kojc7fgqWDNW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke(\"I am Travelling from\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "57GpYpA7WDRl",
        "outputId": "db31feff-35b1-4f26-ef18-2f8501e66a90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am Travelling from First Function to Second Function'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app.stream(input=\"I am Travelling from\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGC-dm8ka8KF",
        "outputId": "fbff031d-89bb-48e4-e0ec-4400e576fec6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Pregel.stream at 0x7f3de2990ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now if you want to check what output came from each Node our Graph traversed, we can do following -\n",
        "\n",
        "input = \"I am Travelling from\"\n",
        "\n",
        "for output in app.stream(input=input):\n",
        "  print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZcfKiq7WDV8",
        "outputId": "613f3d4c-88b7-46c5-908e-ec131bf7ac23"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'node1': 'I am Travelling from First Function'}\n",
            "{'node2': 'I am Travelling from First Function to Second Function'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8gIiW2LwWDaj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Now Trying to Integrate LLM***"
      ],
      "metadata": {
        "id": "VDFdfIKkWDeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "oV0zG8FQWDhi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "secret_name = \"OPENAI_API_KEY\"  # Replace with the name you gave your secret\n",
        "secret_value = userdata.get(secret_name) # Here I am getting the values of API Key from \"Colab Secrets\"\n",
        "\n",
        "# If you are using a seperate .env file then you can use dotenv.load_dotenv to load all your variables stored in file say .env file"
      ],
      "metadata": {
        "id": "LBCjx9tvWDlT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "CiH8r-CVWDs9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\" ,api_key = secret_value,  temperature=0)"
      ],
      "metadata": {
        "id": "9Rfpj-9AWDwk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What is the capital of USA?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIduwmpD4vFZ",
        "outputId": "55a2fe06-ab1a-4e1b-a92d-b8fef3c65cd8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of the United States of America is Washington, D.C.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 14, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-78a833cd-9aa5-4888-86c7-305cae089346-0', usage_metadata={'input_tokens': 14, 'output_tokens': 14, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Hi\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "x76dMwmO4vJQ",
        "outputId": "06fde8ac-12e4-43dd-9e75-64c7dbd160c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Now lets integrate some LLM related code/logic in Function1and Function 2*\n",
        "Simplest we can do is 1. pass some prompt with instructions to LLM with the User input. 2. The output of function 1 can be converted to Upper case and also we can pass the Length of Output.\n"
      ],
      "metadata": {
        "id": "nZo3TTzX4vNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function1(input):\n",
        "  complete_query = \"Your task is to provide only topics based on the user query. Only output the topics among : [India, Cricket, FIFA]. If the asked query doesnot belong to given topic list then say I cannot identify the Topic. \\\n",
        "                    Don't include reasoning. Final resopnse to be under 250 Words only. Following is the user query : \" + input\n",
        "  response = llm.invoke(complete_query)\n",
        "  return response.content\n",
        "\n",
        "def function2(input): # this function will get response/output of function1\n",
        "  upper_response = input.upper()\n",
        "\n",
        "  length = len(input)\n",
        "  final_response = f\"Here is the topic in Upper Case : {upper_response}. \\n Total length of this Topic is {length}\"\n",
        "  return final_response\n"
      ],
      "metadata": {
        "id": "u8DyRNZv4vQ5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_builder = Graph()\n",
        "\n",
        "llm_builder.add_node(\"Agent\", function1)\n",
        "llm_builder.add_node(\"tool\", function2)\n",
        "\n",
        "llm_builder.add_edge(\"Agent\", \"tool\")\n",
        "\n",
        "llm_builder.set_entry_point(\"Agent\")\n",
        "llm_builder.set_finish_point(\"tool\")\n",
        "\n",
        "app = llm_builder.compile()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tmR7CFqA4vVE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Tell me about India\"\n",
        "\n",
        "response = app.invoke(user_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_nA_wJl4vYS",
        "outputId": "8155b6b2-98f8-40fb-8523-d3fdf3633b11"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the topic in Upper Case : INDIA. \n",
            " Total length of this Topic is 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Tell me about USA elections\"\n",
        "\n",
        "response = app.invoke(user_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0vnlHAOhco7",
        "outputId": "cafa6f88-bcb6-497f-dda1-36e3603e57b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the topic in Upper Case : I CANNOT IDENTIFY THE TOPIC.. \n",
            " Total length of this Topic is 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets change the prompt of Agent a bit\n",
        "\n",
        "def function1(input):\n",
        "  complete_query = \"Your task is to provide information in less than 150 Word. Only output for the topics among : [India, Cricket, USA]. If the asked query does not belong to given topic list then say Sorry, I Don't have Information... \\\n",
        "                    Don't include reasoning. Following is the user query : \" + input\n",
        "  response = llm.invoke(complete_query)\n",
        "  return response.content\n",
        "\n",
        "def function2(input): # this function will get response/output of function1\n",
        "  upper_response = input.upper()\n",
        "\n",
        "  length = len(input)\n",
        "  final_response = f\"Here is the topic in Upper Case : {upper_response}. \\n Total length of this Topic is {length}\"\n",
        "  return final_response"
      ],
      "metadata": {
        "id": "1t4qt7534vb1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_builder = Graph()\n",
        "\n",
        "llm_builder.add_node(\"Agent\", function1)\n",
        "llm_builder.add_node(\"tool\", function2)\n",
        "\n",
        "llm_builder.add_edge(\"Agent\", \"tool\")\n",
        "\n",
        "llm_builder.set_entry_point(\"Agent\")\n",
        "llm_builder.set_finish_point(\"tool\")\n",
        "\n",
        "app = llm_builder.compile()\n"
      ],
      "metadata": {
        "id": "iFQqW8JI4vf-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Tell me about India\"\n",
        "\n",
        "response = app.invoke(user_query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy-855Cl4vjx",
        "outputId": "484f01f4-91e8-48a9-e698-cb5d9b64db2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the topic in Upper Case : INDIA IS A COUNTRY LOCATED IN SOUTH ASIA. IT IS KNOWN FOR ITS DIVERSE CULTURE, RICH HISTORY, AND VIBRANT TRADITIONS. WITH A POPULATION OF OVER 1.3 BILLION PEOPLE, INDIA IS THE SECOND MOST POPULOUS COUNTRY IN THE WORLD. IT IS ALSO THE SEVENTH-LARGEST COUNTRY BY LAND AREA. INDIA IS A FEDERAL PARLIAMENTARY DEMOCRATIC REPUBLIC, WITH NEW DELHI AS ITS CAPITAL. THE OFFICIAL LANGUAGES ARE HINDI AND ENGLISH. THE ECONOMY OF INDIA IS ONE OF THE FASTEST-GROWING IN THE WORLD, WITH A STRONG FOCUS ON TECHNOLOGY, AGRICULTURE, AND SERVICES. INDIA IS ALSO FAMOUS FOR ITS CUISINE, INCLUDING DISHES SUCH AS CURRY, BIRYANI, AND DOSA. THE COUNTRY IS HOME TO ICONIC LANDMARKS SUCH AS THE TAJ MAHAL, JAIPUR'S AMBER FORT, AND MUMBAI'S GATEWAY OF INDIA.. \n",
            " Total length of this Topic is 733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Tell me about France\"\n",
        "\n",
        "response = app.invoke(user_query)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7xGdpfeyI-n",
        "outputId": "6c491bae-5eb7-4657-c9e5-6ed7ab417ff4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the topic in Upper Case : SORRY, I DON'T HAVE INFORMATION.... \n",
            " Total length of this Topic is 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TkImoKnryd80"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_FabJweJ3Pxn"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}